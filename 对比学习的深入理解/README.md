# 1.首先就是理解无监督学习@对比学习优化更加简单，这个就是仅仅在特征空间上对数据能够进行区分就好
>这个就是旨在从大量数据中学习同类数据的相同特性，并将其编码为高级表征，之后根据不同的具体任务对学习模型进行微调即可达到优异的效果。例如在分类任务中，首先使用无监督学习算法获得数据的抽象表示，之后只需少量带有标签的数据训练分类器即可。

1.生成式学习/对比式学习。

**生成就是自编码器GAN/VAE等等这类方法为代表，由数据生成数据，使之在整体或者高级语义上与训练数据相近**

**对比式学习着重于学习同类样本之间的共同特征，区分非同类样本之间的不同之处**

与生成式学习比较，对比式学习不需要关注样本上繁琐的细节，**只需要在抽象语义级别的特征空间上学会对数据的区分即可，因此模型以及其优化变得更加简单，且泛化更强。**

<img width="725" alt="image" src="https://user-images.githubusercontent.com/40928887/127867240-ddf439e0-65fe-4e6a-8e2f-069f4c2c46da.png">
