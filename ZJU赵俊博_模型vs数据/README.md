# 1.为啥有必要重新审视?
>原因一: 数据作为AI的能源燃料, 被严重忽视。尤其是学术研究中体现得尤为明显。**(竞赛式的研究体系)**

AI虽然非常火热，每年都有大量的研究论文涌现，但是整体上比起研究探索，但更加像是一个竞赛。

**现在的趋势就是: 在一个相同的公开的标准数据集或者说评测任务上，全世界的研究者都是乐此不疲地开发新的模型结构，努力把模型层数做的越来越深，力图刷榜达到SOTA效果。**

>在这样一个竞赛式的研究体系下，自然没有人去关心数据本身(因为数据已经是固定了，这是一道命题作文)。

>原因二: 数据集是一种稀疏资源，是昂贵的。

**事实上，在许多工业场景下，特别是以交叉学科为背景的(如生物信息/医学影像/制药/材料工业), 真实的数据需要实验人员耗费大量的心血才能得到。如果是需要标签的数据，则又增加了大量的标注成本。**

>原因三: 重新审视, 是为了不偏移航向。**我们不可以偏离这个航向～**

**学术界和工业界都要进行研究，做研究是为了解决实际问题，可是现在我们是在研究解决问题的方法吗？我们发明的模型能够处理实际场景中面临的问题吗？**

# 2.灵魂拷问: 你的模型会被使用吗？
>这个问题非常具有攻击性, 我们还可以让他更激烈一些: **你这奇怪玩意儿真的能用？**

1.能啊，好用的很！我们在这个benchmark上取得了最佳的效果，这太令人振奋了。

2.帅啊兄弟，那换了数据集呢？我这有好几个数据集。

<img width="659" alt="image" src="https://user-images.githubusercontent.com/40928887/134791431-88b9509f-5617-4e26-9dcb-0e6b2e668868.png">

>这个就是一个泛化性能的问题啊，要想泛化性能好，当然是**数据集越来越多就好啦，最好还是不同的领域的不同分布，让模型学到更多的信息！！！**

>那么要是你可以找到好几个数据集，为什么你偏偏就是在一个数据集上训练，你也知道这样的泛化性能大概率不会好，那我拿来怎么用啊？

**就算侥幸能用，我当初多加点高质量数据进去，难道不比这方便？**

>做研究当然需要很多假设条件，甚至是从最理想的情况下出发，不断对理论和模型进行修正，但是在AI这个更新迭代速度极快，应用价值极高的领域，
>这种在一个数据集上刷榜的研究模式是否有点过多地偏离了=实际/

<img width="717" alt="image" src="https://user-images.githubusercontent.com/40928887/134791586-90e285eb-421b-4170-8844-a138285bf95b.png">

**很多模型是没有人使用的～**

# survey
我们重新审视这个 **模型 vs 数据**这个问题, 并不是想说这两者是对立的，在一个AI项目的实施与落地中。模型/数据/部署都是手段而非目的，而很多算法落地困难，就是因为**数据短板的木桶效应造成的。**

<img width="712" alt="image" src="https://user-images.githubusercontent.com/40928887/134791610-afcb5451-53d9-42f0-9874-bdb78e8ee65b.png">


**其实关于工业界的话就是满足工业系统最核心的需求: 稳定性！模型稳定最重要～不需要过于fancy，差不多得了～**

>那么需要用到的数据。会存在那些问题呢？

1)根本没数据！但是我有经费嘿嘿，那么怎么搞呢？**不想花很多的钱，这可能就是涉及到一些数据选择/学习范式方面的研究，比如主动学习等～** 主动学习可以帮我们选择？？

2)**我数据多的是，但是它们标签体系不一样啊！这可能需要一些数据集融合的方法～**

3)我钱多的是，请了一堆人标数据。但是它们标的太烂了，这个全是噪声！这个就是需要noisy-label的研究。

4)实际场景中我没有测试集啊，我怎么检验效果！这时候是一个验证集的最佳选择问题。

5）我怎么知道这数据好还是坏！这是数据点质量评估问题。

6）数据方面的研究还有许许多多的问题，我们不能再视若无睹了！

## 看起来这个数据本身方法面面就是有许多的研究问题，我们不可以视若无睹！！！
# 3.解决数据侧问题的思路
>数据是一种昂贵的稀缺资源，特别是领域性/专业性强的，交叉学科的数据，还要带高质量的标签的就要更加稀缺了～

**对于稀缺资源，必须要合理利用，善加使用，“把数据用在刀刃上”～**

>1.Semi-supervised learning(**这个比如医学影像这种交叉学科**)

比如医学影像这一交叉学科，可以把传统的CV的很多数据迁移过来来用，但是它们缺少医学意义的标签，形成一种“数据多/标签少”的现象。这种场景就是很适合这个半监督学习来利用未标注数据。

>2.Data Augmentation(**数据增强**)
这个就是一个研究也比较深入的领域。仅图像数据就可以各种切分旋转玩出一堆花来，

**近年来也有许多基于生成的方法，特别是对抗生成，都被广泛应用于 数据增强～**

>3.主动学习(Active Learning)模型自主选择training samples

<img width="616" alt="image" src="https://user-images.githubusercontent.com/40928887/134792140-85d2d5d9-3924-4461-9954-d34df066c721.png">

**strongly recommended, 这个核心理念就是: 让模型u 去挑选下一批要学习的数据，这样做的好处就是可以实现模型和数据的同步迭代，就是模型在不断训练的同时，也从全量数据中挑选出了一批最有用的数据～**

>这个就是比如一个爱提问题的学生，他完全清楚自己学的不好的地方在哪里，主动向老师请求这些方面的指导，按照自己的需求去学习～

**使用主动学习，就可以分阶段地去标注训练数据，而不是一次性地投入 大量人力/财力/成本去大规模标注。**

<img width="698" alt="image" src="https://user-images.githubusercontent.com/40928887/134792277-1c9dc48a-ec16-4f65-ad9b-c1da90491a37.png">

# 4.review@（1.如何能够利用好这些数据，将成为AI系统能否赋能各行各业的重要因素/ Data-Centric的研究，也可能是连接起来学术界、工业界的一个重要桥梁。）
>AI研究是一个一体多面的工作，如果我们想要实实在在地推进AI项目的落地，做出真正有用的东西，那么一定要关注数据方面的研究。

**尽管我们常常说现在是大数据现代，但是在工业实际场景和一些交叉领域中，高质量的带标签数据依然是稀缺的，如果能够利用好这些数据，将成为AI系统能否赋能各行各业的重要因素**

