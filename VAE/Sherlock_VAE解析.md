# 1.Autoencoder
>这个就是一种数据的压缩方法,这个特点就是:

1.数据相关程度很高: 这意味着自动编码器只能压缩与训练数据相似的数据，这个其实比较显然，因为使用神经网络提取的特征一般是高度相关于原始的训练集，使用人脸训练出来的自动编码器在压缩自然界动物的图片是表现就会比较差，因为它只学习到了人脸的特征，而没有能够学习到自然界图片的特征；

2.压缩后数据是有损的，这是因为在降维的过程中不可避免的要丢失掉信息；

**到了2012年，人们发现在CNN中使用AE做逐层预训练 可以训练更加深层的网络，但是人们也发现良好的初始化策略要比费劲的逐层预训练要有效得多～**

>2014年出现的Batch Normalization技术也使得更深的网络能够被有效训练～～～～

**2015年通过ResNet我们可以训练任意深度的网络。**

## 现在AE的主要应用是两个方面
1.数据去噪

2.可视化降维

3.然而自动编码器还有着一个功能就是生成数据。

# 2.AE vs GAN (advantage)
1.GAN的话就是生成图片使用的是**随机高斯噪声。这意味着我们并不能生成任意我们指定类型的图片**，这个就是我们没办法决定使用哪种随机噪声可以产生**我们想要的图片，除非我们尝试所有的初始分布。**

>但是AE的话就是我们可以encode这个图片，然后就是获得的分布，就是可以方便我们选择特定的噪声来生成我们想要的图片。

2.这既是生成网络的优点同时又有着一定的局限性，这就是生成网络通过对抗过程来区分“真”的图片和“假”的图片，然而这样得到的图片只是尽可能像真的，但是这并不能保证图片的内容是我们想要的，换句话说，有可能生成网络尽可能的去生成一些背景图案使得其尽可能真，但是里面没有实际的物体。
**GAN的话虽然也挺牛逼的，不过就是可能受到bias，仅仅生成的就是background，而并不会包含这个真正的物体。**

<img width="693" alt="image" src="https://user-images.githubusercontent.com/40928887/133917864-f0f7a953-7f03-4e9c-81c0-0797b352f594.png">
<img width="683" alt="image" src="https://user-images.githubusercontent.com/40928887/133917867-3ead24c5-3ecc-4521-a57c-6fab23ccb7e3.png">
<img width="805" alt="image" src="https://user-images.githubusercontent.com/40928887/133917882-89ca26db-1d8a-4aaa-9030-240937b9603e.png">

效果还是有些模糊的。

# 3.VAE（code就是约束，迫使粗略的标准高斯分布，那么我们就可以自己构造这个random code来生成啦。或者说一定程度可以control）
这个就是AE的升级。
结构和AE类似，也是encoder和decoder。

回忆一下我们在自动编码器中所做的事，我们需要输入一张图片，然后将一张图片编码之后得到一个隐含向量，这比我们随机取一个随机噪声更好，因为这包含着原图片的信息，然后我们隐含向量解码得到与原图片对应的照片。

**AE的话就是我们并没有办法任意生成图片，因为我们没有办法自己去构造这个latent code，我们需要一张图片编码之后我们才知道对应的latent code到底是什么。**

>所以这个时候我们就是可以通过VAE来解决这个问题。

**这个就是仅仅需要我们在编码过程中给它增加一些限制，迫使生成的latent code可以粗略的遵循一个标准的正态分布，这个就是其和一般的AE最大的不同。**

<img width="673" alt="image" src="https://user-images.githubusercontent.com/40928887/133917972-96c92403-4052-4d68-b292-8c6c90793275.png">

## 3.1 正态分布的latent variables?
实际情况下，我们需要在模型的准确率和隐含vector服从**标准正态分布**之间做一个balance，这个准确率就是解码器生成的图片和原图片的相似程度。

**我们可以让网络自己来做这个决定，我们只需要将这两者都做一个loss，然后在将他们求和作为总的loss**

这样这个网络就是可以权衡啦。使用KL divergence来衡量latent code和标准正态分布之间的loss，另外一个还是用MSE来衡量原始图片和生成图片的误差。

<img width="357" alt="image" src="https://user-images.githubusercontent.com/40928887/133918276-44ab8078-4bbe-4b2b-ba40-a17f9c66c542.png">

1.这里我们就是采用一个技巧: "Reparametrization Trick"来解决这个KL divergence的计算问题。

<img width="674" alt="image" src="https://user-images.githubusercontent.com/40928887/133918297-1993faad-dad2-4f7a-8a2c-a10a0b76fd88.png">

**这次我们就是不再是产生一个latnt vector，而是选择生成两个vector，一个表示mean，一个表示标准差，然后就是通过这两个统计量来合成隐vector。**

>这也非常简单，用一个标准正态分布先乘上标准差再加上均值就行了。这里我们默认编码之后的隐含向量是服从一个正态分布的。这个时候我们是想让均值尽可能接近0，标准差尽可能接近1。

**这样泛化能力也是比较强，不过就是这个是直接使用这个生成图片和原始图片的均方误差而不是像GAN那样去对抗去学习，这个就是生成的图片会有点模糊。**

>现在已经有一些工作就是将VAE和GAN结合起来，使用VAE的结构，但是使用对抗网络来训练。

<img width="1190" alt="image" src="https://user-images.githubusercontent.com/40928887/133918363-89e19f24-4fa1-4095-ab2c-f4bac4488996.png">
